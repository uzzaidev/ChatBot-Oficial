/**
 * üß™ CACHE TEST ENDPOINT - PROMPT CACHING
 *
 * Tests Vercel AI Gateway PROMPT CACHE by sending 3 requests with:
 * - SAME system prompt + RAG context (1100+ tokens)
 * - DIFFERENT user questions
 *
 * CRITICAL: OpenAI requires 1024+ tokens for automatic prompt caching!
 * Ref: https://platform.openai.com/docs/guides/prompt-caching
 *
 * Expected behavior:
 * - Request 1: cachedInputTokens = 0 (first time, no cache)
 * - Request 2: cachedInputTokens > 0 (system+context CACHED!)
 * - Request 3: cachedInputTokens > 0 (system+context CACHED!)
 *
 * This tests PROMPT CACHING (economiza tokens), not response caching.
 */

import { NextResponse } from "next/server";
import { generateText } from "ai";
import { createGatewayInstance } from "@/lib/ai-gateway/providers";
import { getSharedGatewayConfig } from "@/lib/ai-gateway/config";

export const dynamic = "force-dynamic";

export async function GET() {
  try {
    console.log("\nüß™ ========== CACHE TEST START ==========\n");

    // Get gateway config
    const gatewayConfig = await getSharedGatewayConfig();

    if (!gatewayConfig?.gatewayApiKey) {
      return NextResponse.json(
        { error: "Gateway API key not configured" },
        { status: 500 }
      );
    }

    const gateway = createGatewayInstance(gatewayConfig.gatewayApiKey);

    // Test configuration - COMPLEX PROMPT for cache testing
    const testModel = "openai/gpt-4o-mini";

    // Long system prompt (1024+ tokens REQUIRED for OpenAI prompt cache)
    // OpenAI automatic prompt caching: https://platform.openai.com/docs/guides/prompt-caching
    const longSystemPrompt = `Voc√™ √© um assistente especializado em atendimento ao cliente de uma empresa de tecnologia.

DIRETRIZES DE ATENDIMENTO:
- Sempre seja educado e profissional
- Use linguagem clara e acess√≠vel
- Confirme entendimento das solicita√ß√µes antes de prosseguir
- Ofere√ßa solu√ß√µes pr√°ticas e detalhadas com exemplos
- Se n√£o souber algo, seja honesto e ofere√ßa alternativas vi√°veis
- Mantenha o tom cordial e emp√°tico durante toda a conversa
- Adapte sua comunica√ß√£o ao n√≠vel t√©cnico do cliente
- Fa√ßa follow-up para garantir a satisfa√ß√£o do cliente

CONHECIMENTO DA EMPRESA:
Nossa empresa oferece os seguintes servi√ßos completos:

1. SUPORTE T√âCNICO
   - Dispon√≠vel 24 horas por dia, 7 dias por semana
   - Atendimento remoto e presencial
   - Tempo de resposta: at√© 30 minutos para casos urgentes
   - Resolu√ß√£o de problemas de hardware e software
   - Manuten√ß√£o preventiva e corretiva
   - Monitoramento proativo de sistemas
   - Backup e recupera√ß√£o de dados
   - Seguran√ßa da informa√ß√£o

2. CONSULTORIA EM TI
   - An√°lise detalhada de infraestrutura atual
   - Recomenda√ß√µes estrat√©gicas para otimiza√ß√£o
   - Planejamento de migra√ß√£o para cloud
   - Avalia√ß√£o de seguran√ßa cibern√©tica
   - Gest√£o de projetos de transforma√ß√£o digital
   - Auditoria de sistemas e processos
   - Redu√ß√£o de custos operacionais
   - Compliance e adequa√ß√£o regulat√≥ria

3. TREINAMENTO CORPORATIVO
   - Capacita√ß√£o de equipes em tecnologias modernas
   - Cursos presenciais e online
   - Certifica√ß√µes oficiais (Microsoft, AWS, Google Cloud)
   - Treinamento customizado conforme necessidade
   - Workshops pr√°ticos e hands-on
   - Acompanhamento p√≥s-treinamento
   - Material did√°tico incluso
   - Avalia√ß√£o de aprendizado

4. DESENVOLVIMENTO DE SOFTWARE
   - Aplica√ß√µes web e mobile customizadas
   - Integra√ß√£o de sistemas legados
   - APIs e microsservi√ßos
   - Desenvolvimento √°gil (Scrum/Kanban)
   - Testes automatizados
   - Deploy e CI/CD
   - Manuten√ß√£o evolutiva
   - Documenta√ß√£o t√©cnica completa

HOR√ÅRIOS DE ATENDIMENTO:
- Suporte T√©cnico: 24 horas por dia, 7 dias por semana, incluindo feriados
- Consultoria: Segunda a Sexta-feira, das 9h √†s 18h (hor√°rio de Bras√≠lia)
- Treinamento: Agendamento pr√©vio necess√°rio, hor√°rios flex√≠veis
- Desenvolvimento: Sob demanda, com reuni√µes agendadas conforme projeto
- Atendimento de Emerg√™ncia: Dispon√≠vel 24/7 para clientes Premium

POL√çTICA DE PRE√áOS E PACOTES:

PLANO B√ÅSICO:
- Suporte T√©cnico: R$ 150/hora
- Consultoria: R$ 300/hora
- Treinamento: R$ 500/dia por participante
- Desenvolvimento: R$ 120/hora

PLANO PROFISSIONAL (desconto 15%):
- Suporte T√©cnico: R$ 127,50/hora
- Consultoria: R$ 255/hora
- Treinamento: R$ 425/dia por participante
- Desenvolvimento: R$ 102/hora
- Inclui: 5 horas mensais de suporte gr√°tis

PLANO EMPRESARIAL (desconto 25%):
- Suporte T√©cnico: R$ 112,50/hora
- Consultoria: R$ 225/hora
- Treinamento: R$ 375/dia por participante
- Desenvolvimento: R$ 90/hora
- Inclui: 15 horas mensais de suporte gr√°tis
- Gerente de conta dedicado
- Prioridade no atendimento

FORMAS DE PAGAMENTO:
- Cart√£o de cr√©dito (at√© 12x sem juros)
- Boleto banc√°rio (√† vista com 5% desconto)
- Transfer√™ncia banc√°ria
- PIX (√† vista com 5% desconto)
- Faturamento mensal para empresas

CONTATOS E CANAIS:
- Email: suporte@empresa.com
- Telefone: (11) 9999-9999
- WhatsApp Business: (11) 9999-9999
- Website: www.empresa.com.br
- Chat Online: Dispon√≠vel no site 24/7
- Portal do Cliente: https://portal.empresa.com.br

POL√çTICAS IMPORTANTES:
1. Garantia de satisfa√ß√£o de 30 dias
2. SLA de 99.9% de uptime para clientes Premium
3. Pol√≠tica de privacidade rigorosa (LGPD compliant)
4. Contratos flex√≠veis sem fidelidade m√≠nima
5. Cancelamento com 30 dias de aviso pr√©vio

Lembre-se de sempre coletar informa√ß√µes relevantes do cliente antes de sugerir solu√ß√µes espec√≠ficas, incluindo:
- Porte da empresa (n√∫mero de funcion√°rios)
- Setor de atua√ß√£o
- Infraestrutura atual (on-premise, cloud, h√≠brido)
- Budget dispon√≠vel
- Urg√™ncia da demanda
- Problemas espec√≠ficos enfrentados`;

    // RAG context (~300 tokens) - will also be CACHED
    const ragContext = `

INFORMA√á√ïES ADICIONAIS DO CONHECIMENTO BASE:

FAQ - Perguntas Frequentes:
Q: Como funciona o suporte t√©cnico?
A: Nosso suporte funciona 24/7. Voc√™ pode abrir um chamado por email, telefone ou WhatsApp e ser√° atendido em at√© 30 minutos.

Q: Qual a diferen√ßa entre consultoria e suporte?
A: Suporte √© para resolver problemas imediatos. Consultoria √© para an√°lise estrat√©gica e planejamento de melhorias.

Q: Voc√™s atendem empresas de qualquer tamanho?
A: Sim! Atendemos desde pequenas startups at√© grandes corpora√ß√µes.

CASOS DE SUCESSO:
- Empresa A: Redu√ß√£o de 70% no tempo de resposta
- Empresa B: Economia de R$ 50mil/m√™s em infraestrutura
- Empresa C: Aumento de 40% na produtividade da equipe`;

    // Different user questions for each request (but system/context stays SAME)
    const userQuestions = [
      "Qual o hor√°rio de funcionamento do suporte t√©cnico?",
      "Quanto custa uma consultoria?",
      "Como fa√ßo para contratar treinamento?"
    ];

    const results = [];

    // Run 3 requests with DIFFERENT questions but SAME system+context
    for (let i = 1; i <= 3; i++) {
      console.log(`\n--- Request ${i}/3 ---`);
      console.log(`Question: "${userQuestions[i - 1]}"`);

      const startTime = Date.now();

      const testMessages = [
        {
          role: "system" as const,
          content: longSystemPrompt + ragContext, // ~800 tokens - should be CACHED in req 2 & 3
        },
        {
          role: "user" as const,
          content: userQuestions[i - 1], // Different question each time
        },
      ];

      const result = await generateText({
        model: gateway(testModel),
        messages: testMessages,
        temperature: 0, // üî• CRITICAL for cache
        experimental_telemetry: { isEnabled: true },
      });

      const latencyMs = Date.now() - startTime;
      const headers = result.response?.headers || {};
      const usage = result.usage;

      const cacheStatus = headers["x-vercel-cache"] || "UNKNOWN";

      console.log(`Request ${i} Results:`, {
        cacheStatus,
        latencyMs,
        inputTokens: usage?.inputTokens || 0,
        cachedInputTokens: usage?.cachedInputTokens || 0, // üéØ KEY METRIC!
        outputTokens: usage?.outputTokens || 0,
        cachePercentage: usage?.inputTokens
          ? Math.round((usage.cachedInputTokens || 0) / (usage.inputTokens + (usage.cachedInputTokens || 0)) * 100)
          : 0,
      });

      results.push({
        request: i,
        question: userQuestions[i - 1],
        cacheStatus,
        latencyMs,
        text: result.text,
        usage: {
          inputTokens: usage?.inputTokens || 0,
          outputTokens: usage?.outputTokens || 0,
          totalTokens: usage?.totalTokens || 0,
          cachedInputTokens: usage?.cachedInputTokens || 0, // üéØ STORE THIS!
          reasoningTokens: usage?.reasoningTokens || 0,
        },
        allHeaders: Object.keys(headers),
        cacheHeaders: {
          "x-vercel-cache": headers["x-vercel-cache"],
          "x-vercel-ai-cache-status": headers["x-vercel-ai-cache-status"],
          "x-vercel-ai-provider": headers["x-vercel-ai-provider"],
          "x-vercel-ai-model": headers["x-vercel-ai-model"],
        },
      });

      // Delay between requests
      if (i < 3) {
        await new Promise((resolve) => setTimeout(resolve, 1000)); // 1 second
      }
    }

    console.log("\nüß™ ========== CACHE TEST END ==========\n");

    // Analysis - Focus on PROMPT CACHE (cachedInputTokens)
    const analysis = {
      expectedBehavior: {
        request1: "No cache (first time) - cachedInputTokens = 0",
        request2: "Prompt cached - cachedInputTokens > 0",
        request3: "Prompt cached - cachedInputTokens > 0",
      },
      actualBehavior: {
        request1: {
          inputTokens: results[0].usage.inputTokens,
          cachedInputTokens: results[0].usage.cachedInputTokens,
        },
        request2: {
          inputTokens: results[1].usage.inputTokens,
          cachedInputTokens: results[1].usage.cachedInputTokens,
        },
        request3: {
          inputTokens: results[2].usage.inputTokens,
          cachedInputTokens: results[2].usage.cachedInputTokens,
        },
      },
      cacheWorking:
        results[1].usage.cachedInputTokens > 0 &&
        results[2].usage.cachedInputTokens > 0,
      cacheStats: {
        totalCachedTokens: results.reduce((sum, r) => sum + r.usage.cachedInputTokens, 0),
        avgCacheRate: Math.round(
          results.reduce((sum, r) => {
            const total = r.usage.inputTokens + r.usage.cachedInputTokens;
            return sum + (total > 0 ? (r.usage.cachedInputTokens / total) * 100 : 0);
          }, 0) / results.length
        ),
        tokensSaved: results[1].usage.cachedInputTokens + results[2].usage.cachedInputTokens,
      },
      latencyComparison: {
        firstRequest: results[0].latencyMs,
        cachedRequests: [results[1].latencyMs, results[2].latencyMs],
      },
    };

    return NextResponse.json({
      success: true,
      testConfig: {
        model: testModel,
        temperature: 0,
        messageCount: 2, // system + user
        systemTokensApprox: 1100, // 1024+ required for OpenAI prompt cache
        cacheRequirement: "OpenAI requires 1024+ tokens for automatic prompt caching",
      },
      results,
      analysis,
    });
  } catch (error: any) {
    console.error("[Cache Test] Error:", error);
    return NextResponse.json(
      {
        error: error.message || "Unknown error",
        stack: error.stack,
      },
      { status: 500 }
    );
  }
}

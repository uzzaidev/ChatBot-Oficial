# Mapeamento de Chamadas API - MigraÃ§Ã£o para AI Gateway

> **Objetivo:** Centralizar TODAS as chamadas de modelos de IA atravÃ©s do Vercel AI Gateway para obter cache, economia, monitoramento e fallback automÃ¡tico.

---

## ğŸ“Š Status Atual: Resumo Executivo

| API Type | Modelo Atual | Modelo Gateway | AÃ§Ã£o | Budget Tracking |
|----------|--------------|----------------|------|-----------------|
| **Chat (main)** | gpt-4o-mini / llama-3.3-70b | `openai/gpt-4o-mini` | âœ… No Gateway | âœ… `gateway_usage_logs` |
| **Embeddings** | text-embedding-3-small | `openai/text-embedding-3-small` | ğŸ”„ Migrar | â†’ `gateway_usage_logs` |
| **Vision** | gpt-4o | `openai/gpt-4o` | ğŸ”„ Migrar | â†’ `gateway_usage_logs` |
| **PDF Summary** | gpt-4o | `openai/gpt-4o` | ğŸ”„ Migrar | â†’ `gateway_usage_logs` |
| **Whisper** | whisper-1 | âŒ N/A | âš ï¸ SDK Direto | âš ï¸ Melhorar tracking |
| **TTS (OpenAI)** | tts-1-hd | âŒ N/A | âš ï¸ SDK Direto | âš ï¸ Melhorar tracking |
| **TTS (ElevenLabs)** | eleven_multilingual_v1 | âŒ N/A | âš ï¸ SDK Direto | âœ… `unified_usage_logs` |

**Legenda:**
- âœ… No Gateway = Funcionando via AI Gateway
- ğŸ”„ Migrar = Pode migrar para Gateway (tem suporte)
- âš ï¸ SDK Direto = Gateway nÃ£o suporta, mantÃ©m SDK direto + tracking

---

## ğŸ¯ Plano de AÃ§Ã£o Atualizado

### âœ… MIGRAR para Gateway (Tem Suporte)

| API | Modelo Gateway | BenefÃ­cio | Prioridade |
|-----|----------------|-----------|------------|
| **Embeddings** | `openai/text-embedding-3-small` | Dashboard + tracking unificado | ğŸ”¥ Alta |
| **Vision** | `openai/gpt-4o` | Prompt cache (~60% economia) | ğŸ”¥ Alta |
| **PDF Summary** | `openai/gpt-4o` | Prompt cache (~70% economia) | ğŸ”¶ MÃ©dia |

### âš ï¸ MANTER Direto + Melhorar Tracking

| API | Modelo | Tracking Atual | Tracking NecessÃ¡rio |
|-----|--------|----------------|---------------------|
| **Whisper** | whisper-1 | âœ… Tokens (estimados) | âš ï¸ Budget em R$ e tokens |
| **TTS** | tts-1-hd | âœ… Caracteres + R$ | âš ï¸ Budget em tokens |
| **TTS (ElevenLabs)** | eleven_multilingual_v1 | âœ… Completo | âœ… OK |

---

## ğŸ”§ Melhorias de Tracking para SDKs Diretos

### Problema Atual

**Whisper e TTS (OpenAI)** usam SDK direto (Gateway nÃ£o suporta), mas o tracking estÃ¡ **incompleto**:

âŒ NÃ£o salvam em `gateway_usage_logs` (tabela unificada)
âŒ NÃ£o tÃªm budget control por cliente
âŒ NÃ£o incrementam `client_budgets.tokens_used_current_period`

### SoluÃ§Ã£o: Unificar Tracking

**Objetivo:** SDKs diretos devem ter o **mesmo tracking** que APIs no Gateway.

#### 1. Whisper - Melhorar Tracking

**Arquivo:** `src/lib/openai.ts:48-123`

**Tracking atual:**
```typescript
await logAPIUsage({
  clientId,
  phone,
  apiType: "whisper",
  provider: "openai",
  modelName: "whisper-1",
  inputUnits: estimatedDurationSeconds, // âš ï¸ segundos, nÃ£o tokens
  latencyMs,
});
```

**Problemas:**
- Salva em `usage_logs` (legacy)
- NÃ£o calcula custo em R$
- NÃ£o incrementa budget
- inputUnits = segundos (deveria ser tokens estimados)

**SoluÃ§Ã£o proposta:**
```typescript
// Calcular tokens estimados (Whisper cobra por minuto, nÃ£o por token)
const estimatedTokens = Math.ceil((estimatedDurationSeconds / 60) * 1000);

// Calcular custo ($0.006/minuto)
const costUSD = (estimatedDurationSeconds / 60) * 0.006;

// Salvar em gateway_usage_logs (unificado)
await logGatewayUsage(
  clientId,
  conversationId,
  phone,
  {
    provider: 'openai',
    model: 'whisper-1',
    inputTokens: estimatedTokens,
    outputTokens: 0,
    totalTokens: estimatedTokens,
    cachedInputTokens: 0,
    costUSD,
    latencyMs,
    metadata: {
      audioSeconds: estimatedDurationSeconds,
      apiType: 'whisper'
    }
  }
);

// âœ… Incrementar budget automaticamente (via logGatewayUsage)
```

**BenefÃ­cios:**
- âœ… Aparece no dashboard unificado
- âœ… Budget control por cliente
- âœ… ConversÃ£o USD â†’ BRL automÃ¡tica
- âœ… Tracking de tokens (mesmo que estimados)

---

#### 2. TTS (OpenAI) - Melhorar Tracking

**Arquivo:** `src/nodes/convertTextToSpeech.ts:229-262`

**Tracking atual:**
```typescript
// Legacy tracking
await supabase.from("tts_usage_logs").insert({
  client_id: clientId,
  phone: "system",
  event_type: "generated",
  text_length: text.length,
  from_cache: false,
});

// Unified tracking
await trackUnifiedUsage({
  clientId,
  phone: "system",
  apiType: "tts",
  provider: usedProvider,
  modelName,
  characters: text.length, // âš ï¸ caracteres, nÃ£o tokens
  costUSD,
  latencyMs: 0,
});
```

**Problemas:**
- Usa `characters` (nÃ£o tokens)
- NÃ£o incrementa budget em tokens
- Salva em `unified_usage_logs` (separado de `gateway_usage_logs`)

**SoluÃ§Ã£o proposta:**
```typescript
// Estimar tokens (aproximadamente 1 token = 4 caracteres)
const estimatedTokens = Math.ceil(text.length / 4);

// Custo jÃ¡ calculado corretamente
const costUSD = model === "tts-1-hd"
  ? (text.length / 1_000_000) * 15.0
  : (text.length / 1_000_000) * 7.5;

// Salvar em gateway_usage_logs (unificado)
await logGatewayUsage(
  clientId,
  conversationId,
  phone,
  {
    provider: 'openai',
    model: model,
    inputTokens: estimatedTokens,
    outputTokens: 0,
    totalTokens: estimatedTokens,
    cachedInputTokens: 0,
    costUSD,
    latencyMs: 0,
    metadata: {
      characters: text.length,
      voice,
      speed,
      apiType: 'tts',
      fromCache: false
    }
  }
);
```

**BenefÃ­cios:**
- âœ… Tracking unificado com chat/vision/embeddings
- âœ… Budget control por tokens
- âœ… Dashboard Ãºnico

---

### 3. Budget Control - Client Budgets

**Objetivo:** Todos os clientes devem ter limite de budget em **tokens** e **R$**.

**Tabela:** `client_budgets`

```sql
CREATE TABLE client_budgets (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  client_id UUID NOT NULL REFERENCES clients(id),

  -- Budget em tokens
  tokens_limit_per_period INTEGER, -- ex: 1_000_000 tokens/mÃªs
  tokens_used_current_period INTEGER DEFAULT 0,
  tokens_period_start TIMESTAMPTZ DEFAULT NOW(),
  tokens_period_end TIMESTAMPTZ,

  -- Budget em reais
  brl_limit_per_period NUMERIC(10,2), -- ex: R$ 100,00/mÃªs
  brl_used_current_period NUMERIC(10,2) DEFAULT 0.00,
  brl_period_start TIMESTAMPTZ DEFAULT NOW(),
  brl_period_end TIMESTAMPTZ,

  -- Alertas
  alert_threshold_percentage INTEGER DEFAULT 80, -- alerta em 80%
  alert_sent BOOLEAN DEFAULT FALSE,

  -- Status
  is_active BOOLEAN DEFAULT TRUE,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);
```

**FunÃ§Ã£o de incremento:**
```typescript
// src/lib/ai-gateway/usage-tracking.ts

export const logGatewayUsage = async (
  clientId: string,
  conversationId: string | null,
  phone: string | null,
  usage: {
    provider: string;
    model: string;
    inputTokens: number;
    outputTokens: number;
    costUSD: number;
    // ...
  }
) => {
  // 1. Salvar log
  await supabase.from('gateway_usage_logs').insert({
    client_id: clientId,
    conversation_id: conversationId,
    phone,
    provider: usage.provider,
    model: usage.model,
    input_tokens: usage.inputTokens,
    output_tokens: usage.outputTokens,
    cost_usd: usage.costUSD,
    cost_brl: await convertUSDtoBRL(usage.costUSD),
    // ...
  });

  // 2. Incrementar budget do cliente
  const costBRL = await convertUSDtoBRL(usage.costUSD);
  const totalTokens = usage.inputTokens + usage.outputTokens;

  await supabase.rpc('increment_client_budget', {
    p_client_id: clientId,
    p_tokens: totalTokens,
    p_cost_brl: costBRL
  });

  // 3. Verificar se excedeu limite
  const { data: budget } = await supabase
    .from('client_budgets')
    .select('*')
    .eq('client_id', clientId)
    .single();

  if (budget) {
    const tokenUsagePercent = (budget.tokens_used_current_period / budget.tokens_limit_per_period) * 100;
    const brlUsagePercent = (budget.brl_used_current_period / budget.brl_limit_per_period) * 100;

    if (tokenUsagePercent >= budget.alert_threshold_percentage ||
        brlUsagePercent >= budget.alert_threshold_percentage) {
      await sendBudgetAlert(clientId, {
        tokenUsagePercent,
        brlUsagePercent
      });
    }
  }
};
```

**RPC Function (PostgreSQL):**
```sql
CREATE OR REPLACE FUNCTION increment_client_budget(
  p_client_id UUID,
  p_tokens INTEGER,
  p_cost_brl NUMERIC
)
RETURNS VOID AS $$
BEGIN
  INSERT INTO client_budgets (
    client_id,
    tokens_used_current_period,
    brl_used_current_period
  )
  VALUES (
    p_client_id,
    p_tokens,
    p_cost_brl
  )
  ON CONFLICT (client_id) DO UPDATE SET
    tokens_used_current_period = client_budgets.tokens_used_current_period + p_tokens,
    brl_used_current_period = client_budgets.brl_used_current_period + p_cost_brl,
    updated_at = NOW();
END;
$$ LANGUAGE plpgsql;
```

---

### 4. Dashboard de Budget

**PÃ¡gina:** `/dashboard/ai-gateway/budget`

**Cards:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tokens Usados        â”‚  â”‚ Custo em Reais       â”‚  â”‚ Status do PerÃ­odo    â”‚
â”‚                      â”‚  â”‚                      â”‚  â”‚                      â”‚
â”‚ 750K / 1M            â”‚  â”‚ R$ 78,50 / R$ 100    â”‚  â”‚ RenovaÃ§Ã£o: 5 dias    â”‚
â”‚ [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 75%     â”‚  â”‚ [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 78.5%   â”‚  â”‚ ğŸ“Š Dentro do limite  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Tabela de uso por API:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API         â”‚ Requests   â”‚ Tokens       â”‚ % Budget   â”‚ Custo (R$)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Chat        â”‚ 1,234      â”‚ 500K (50%)   â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â”‚ R$ 45,20     â”‚
â”‚ Embeddings  â”‚ 456        â”‚ 150K (15%)   â”‚ â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘   â”‚ R$ 8,30      â”‚
â”‚ Vision      â”‚ 89         â”‚ 80K (8%)     â”‚ â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘   â”‚ R$ 18,50     â”‚
â”‚ Whisper     â”‚ 234        â”‚ 15K (1.5%)   â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   â”‚ R$ 4,80      â”‚
â”‚ TTS         â”‚ 156        â”‚ 5K (0.5%)    â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   â”‚ R$ 1,70      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1. âœ… Chat Principal (JÃ NO GATEWAY)

### Status: âœ… FUNCIONANDO

**Arquivo:** [src/nodes/generateAIResponse.ts](src/nodes/generateAIResponse.ts)

**Como funciona:**
```typescript
import { callAI } from "@/lib/ai-gateway";

const result = await callAI({
  messages,
  tools,
  config,
  clientId,
  phone,
  conversationId
});
```

**Modelos suportados:**
- âœ… OpenAI: gpt-4o, gpt-4o-mini
- âœ… Groq: llama-3.3-70b-versatile
- âœ… Anthropic: claude-3-5-sonnet
- âœ… Google: gemini-2.0-flash-exp

**BenefÃ­cios atuais:**
- âœ… Prompt cache (economiza 60-70% tokens)
- âœ… Dashboard Vercel com mÃ©tricas
- âœ… Fallback automÃ¡tico entre providers
- âœ… Tracking multi-tenant (`gateway_usage_logs`)

---

## 2. âŒ Whisper (TranscriÃ§Ã£o de Ãudio)

### Status: âŒ CHAMADA DIRETA

### Onde estÃ¡ sendo chamado:

**1. FunÃ§Ã£o principal:**
- **Arquivo:** [src/lib/openai.ts:48-123](src/lib/openai.ts#L48)
- **FunÃ§Ã£o:** `transcribeAudio()`
- **Modelo:** `whisper-1`

```typescript
const client = new OpenAI({ apiKey: resolvedApiKey });

const transcription = await client.audio.transcriptions.create({
  file: transcriptionFile,
  model: "whisper-1",
  language: "pt",
});
```

**2. Wrapper node:**
- **Arquivo:** [src/nodes/transcribeAudio.ts](src/nodes/transcribeAudio.ts)
- **Usa:** `transcribeAudioWithWhisper()` do `@/lib/openai`

### Por que estÃ¡ chamando direto:
- Implementado antes do AI Gateway
- Usa SDK do OpenAI (`openai` npm package)

### Volume de uso:
- ğŸ”¥ **Alto** - Ãudios sÃ£o comuns em WhatsApp

### Tracking atual:
- âœ… JÃ¡ salva em `usage_logs` via `logAPIUsage()`
- âœ… Tracking por `client_id`
- âš ï¸ Mas **nÃ£o usa** `gateway_usage_logs` (tabela nova)

### Como migrar:

**OpÃ§Ã£o 1: Gateway direto (se suportado)**
```typescript
// Verificar se AI Gateway suporta Whisper
import { createGatewayInstance } from '@/lib/ai-gateway/providers';

const gateway = createGatewayInstance(gatewayApiKey);
// Usar gateway('openai/whisper-1') se disponÃ­vel
```

**OpÃ§Ã£o 2: Manter direto + unificar tracking**
```typescript
// Se Gateway NÃƒO suportar Whisper, apenas centralizar tracking
await logGatewayUsage(
  clientId,
  conversationId,
  phone,
  {
    provider: 'openai',
    model: 'whisper-1',
    inputTokens: estimatedTokens,
    outputTokens: 0,
    costUSD: (estimatedDurationSeconds / 60) * 0.006, // $0.006/min
    latencyMs
  }
);
```

---

## 3. âŒ Embeddings (RAG / Busca SemÃ¢ntica)

### Status: âŒ CHAMADA DIRETA

### Onde estÃ¡ sendo chamado:

**1. FunÃ§Ã£o principal:**
- **Arquivo:** [src/lib/openai.ts:269-336](src/lib/openai.ts#L269)
- **FunÃ§Ã£o:** `generateEmbedding()`
- **Modelo:** `text-embedding-3-small`

```typescript
const client = new OpenAI({ apiKey: resolvedApiKey });

const response = await client.embeddings.create({
  model: "text-embedding-3-small",
  input: text,
});
```

**2. Usado por:**
- **RAG Search:** [src/nodes/searchDocumentInKnowledge.ts:181](src/nodes/searchDocumentInKnowledge.ts#L181)
- **Document Upload:** [src/app/api/documents/upload/route.ts](src/app/api/documents/upload/route.ts)
- **Chunking:** [src/nodes/processDocumentWithChunking.ts](src/nodes/processDocumentWithChunking.ts)

### Por que estÃ¡ chamando direto:
- Embeddings implementados antes do Gateway
- API de embeddings Ã© diferente de chat (nÃ£o usa `generateText()`)

### Volume de uso:
- ğŸ”¥ **MÃ©dio-Alto** - Gera embedding para:
  - Cada chunk de documento (upload)
  - Cada busca RAG (por conversa)

### Tracking atual:
- âœ… JÃ¡ salva em `usage_logs` via `logAPIUsage()`
- âœ… Tracking por `client_id`

### Como migrar:

**Verificar suporte do Gateway:**
```typescript
// Gateway pode suportar embeddings via Vercel AI SDK:
import { embed } from 'ai';
import { createGatewayInstance } from '@/lib/ai-gateway/providers';

const gateway = createGatewayInstance(gatewayApiKey);

const { embedding } = await embed({
  model: gateway('openai/text-embedding-3-small'),
  value: text
});
```

**Se nÃ£o suportado, manter direto + unificar tracking:**
```typescript
await logGatewayUsage(
  clientId,
  conversationId,
  phone,
  {
    provider: 'openai',
    model: 'text-embedding-3-small',
    inputTokens: usage.prompt_tokens,
    outputTokens: 0,
    costUSD: (usage.prompt_tokens / 1_000_000) * 0.02, // $0.02/1M tokens
    latencyMs
  }
);
```

---

## 4. âŒ Vision (AnÃ¡lise de Imagens)

### Status: âŒ CHAMADA DIRETA

### Onde estÃ¡ sendo chamado:

**Arquivo:** [src/lib/openai.ts:172-267](src/lib/openai.ts#L172)
- **FunÃ§Ã£o:** `analyzeImageFromBuffer()`
- **Modelo:** `gpt-4o` (vision)

```typescript
const client = new OpenAI({ apiKey: resolvedApiKey });

const response = await client.chat.completions.create({
  model: "gpt-4o",
  messages: [
    {
      role: "user",
      content: [
        { type: "text", text: prompt },
        { type: "image_url", image_url: { url: dataUrl } }
      ]
    }
  ],
  max_tokens: 1000,
});
```

### Por que estÃ¡ chamando direto:
- Usa formato especial de mensagem (multimodal)
- Implementado antes do Gateway

### Volume de uso:
- ğŸ”¶ **MÃ©dio** - Quando usuÃ¡rio envia imagem no WhatsApp

### Tracking atual:
- âœ… JÃ¡ salva em `usage_logs` via `logAPIUsage()`
- âœ… Tracking por `client_id` e `phone`

### Como migrar:

**Gateway provavelmente suporta Vision:**
```typescript
import { generateText } from 'ai';
import { createGatewayInstance } from '@/lib/ai-gateway/providers';

const gateway = createGatewayInstance(gatewayApiKey);

const result = await generateText({
  model: gateway('openai/gpt-4o'),
  messages: [
    {
      role: 'user',
      content: [
        { type: 'text', text: prompt },
        { type: 'image', image: imageBuffer } // ou dataUrl
      ]
    }
  ]
});
```

**BenefÃ­cios da migraÃ§Ã£o:**
- âœ… Prompt cache (se prompt for longo)
- âœ… Dashboard Vercel
- âœ… Fallback automÃ¡tico

---

## 5. âŒ TTS - Text-to-Speech (OpenAI)

### Status: âŒ CHAMADA DIRETA

### Onde estÃ¡ sendo chamado:

**Arquivo:** [src/nodes/convertTextToSpeech.ts:169-181](src/nodes/convertTextToSpeech.ts#L169)
- **Modelos:** `tts-1`, `tts-1-hd`
- **Voices:** alloy, echo, fable, onyx, nova, shimmer

```typescript
const openai = new OpenAI({ apiKey: finalOpenaiKey });

const mp3Response = await openai.audio.speech.create({
  model: selectedModel,
  voice: selectedVoice,
  input: text,
  speed: speed,
  response_format: "mp3",
});
```

### Por que estÃ¡ chamando direto:
- API de Ã¡udio (nÃ£o Ã© chat/text generation)
- Retorna Ã¡udio binÃ¡rio (nÃ£o text)

### Volume de uso:
- ğŸ”¶ **MÃ©dio** - Quando bot responde com Ã¡udio
- âœ… **Tem cache prÃ³prio** (`tts_cache` table)

### Tracking atual:
- âœ… Tracking em `tts_usage_logs`
- âœ… Tracking unificado em `unified_usage_logs` via `trackUnifiedUsage()`

### Como migrar:

**âš ï¸ Verificar se Gateway suporta TTS:**
- TTS nÃ£o Ã© modelo de text generation
- Provavelmente **NÃƒO suportado** pelo Vercel AI Gateway

**RecomendaÃ§Ã£o:**
- âœ… Manter chamada direta (jÃ¡ tem cache prÃ³prio)
- âœ… Unificar tracking (jÃ¡ usa `trackUnifiedUsage()`)
- âŒ NÃ£o migrar para Gateway (nÃ£o aplicÃ¡vel)

---

## 6. âŒ TTS - ElevenLabs

### Status: âŒ CHAMADA DIRETA

### Onde estÃ¡ sendo chamado:

**Arquivo:** [src/nodes/convertTextToSpeech.ts:112](src/nodes/convertTextToSpeech.ts#L112)
- **Provider:** ElevenLabs
- **FunÃ§Ã£o:** `elevenLabsTTS()`
- **Modelos:** eleven_monolingual_v1, eleven_multilingual_v1, eleven_turbo_v2

### Por que estÃ¡ chamando direto:
- Provider alternativo (nÃ£o Ã© OpenAI/Anthropic/Groq/Google)
- API prÃ³pria da ElevenLabs

### Volume de uso:
- ğŸ”» **Baixo** - Usado opcionalmente (fallback do OpenAI TTS)

### Como migrar:

**âŒ Gateway NÃƒO suporta ElevenLabs**
- Vercel AI Gateway sÃ³ suporta: OpenAI, Anthropic, Groq, Google
- ElevenLabs nÃ£o estÃ¡ na lista

**RecomendaÃ§Ã£o:**
- âœ… Manter chamada direta
- âœ… Tracking jÃ¡ estÃ¡ unificado via `trackUnifiedUsage()`

---

## 7. âŒ PDF Summary (GPT-4o)

### Status: âŒ CHAMADA DIRETA

### Onde estÃ¡ sendo chamado:

**Arquivo:** [src/lib/openai.ts:357-446](src/lib/openai.ts#L357)
- **FunÃ§Ã£o:** `summarizePDFContent()`
- **Modelo:** `gpt-4o`

```typescript
const client = new OpenAI({ apiKey: resolvedApiKey });

const response = await client.chat.completions.create({
  model: "gpt-4o",
  messages: [{ role: "user", content: prompt }],
  max_tokens: 1500,
});
```

### Por que estÃ¡ chamando direto:
- Implementado antes do Gateway
- FunÃ§Ã£o utilitÃ¡ria especÃ­fica

### Volume de uso:
- ğŸ”» **Baixo** - SÃ³ ao fazer upload de PDF

### Tracking atual:
- âœ… JÃ¡ salva em `usage_logs` via `logAPIUsage()`

### Como migrar:

**FÃ¡cil migraÃ§Ã£o:**
```typescript
import { generateText } from 'ai';
import { createGatewayInstance } from '@/lib/ai-gateway/providers';

const gateway = createGatewayInstance(gatewayApiKey);

const result = await generateText({
  model: gateway('openai/gpt-4o'),
  prompt: prompt,
  maxTokens: 1500
});
```

**BenefÃ­cios:**
- âœ… Prompt cache (prompt Ã© longo ~12K caracteres)
- âœ… Dashboard
- âœ… Economia

---

## 8. âŒ Groq Chat (Legacy)

### Status: âŒ CHAMADA DIRETA (mas nÃ£o usado)

### Onde estÃ¡:

**Arquivo:** [src/lib/groq.ts:66-129](src/lib/groq.ts#L66)
- **FunÃ§Ã£o:** `generateChatCompletion()`
- **Modelos:** llama-3.3-70b-versatile

### Por que existe:
- ImplementaÃ§Ã£o legacy antes do Gateway
- **NÃƒO estÃ¡ sendo usada** (substituÃ­da por `callAI()`)

### Como migrar:

**âœ… JÃ¡ migrado!** - `generateAIResponse.ts` usa `callAI()` que jÃ¡ suporta Groq via Gateway.

**AÃ§Ã£o recomendada:**
- âš ï¸ Deprecar `src/lib/groq.ts`
- âš ï¸ Remover imports nÃ£o usados

---

## 9. âŒ Detect Repetition (Fast Track Router)

### Status: âš ï¸ VERIFICAR

**Arquivo:** [src/nodes/detectRepetition.ts](src/nodes/detectRepetition.ts)

**Precisa verificar:**
- Se usa `callAI()` (Gateway) ou chamada direta
- Modelo usado
- Se tem prompt cache ativo

---

## ğŸ“‹ Plano de MigraÃ§Ã£o

### Fase 1: MigraÃ§Ãµes PrioritÃ¡rias (Alta economia)

#### 1.1. Whisper (ğŸ”¥ Alta prioridade)
- [ ] Verificar se Vercel AI Gateway suporta Whisper
- [ ] Se sim: migrar para `gateway('openai/whisper-1')`
- [ ] Se nÃ£o: unificar tracking em `gateway_usage_logs`
- [ ] Testar com Ã¡udio real
- [ ] Validar custos no dashboard

#### 1.2. Embeddings (ğŸ”¥ Alta prioridade)
- [ ] Verificar suporte do Gateway para embeddings
- [ ] Migrar `generateEmbedding()` para usar Gateway
- [ ] Atualizar RAG search
- [ ] Atualizar document upload
- [ ] Testar busca semÃ¢ntica
- [ ] Validar custos

#### 1.3. Vision (ğŸ”¥ Alta prioridade)
- [ ] Migrar `analyzeImageFromBuffer()` para Gateway
- [ ] Testar com imagens reais
- [ ] Validar cache (prompt pode ser cacheado)
- [ ] Validar custos

### Fase 2: MigraÃ§Ãµes SecundÃ¡rias

#### 2.1. PDF Summary (ğŸ”¶ MÃ©dia prioridade)
- [ ] Migrar `summarizePDFContent()` para Gateway
- [ ] Aproveitar prompt cache (prompt Ã© longo)
- [ ] Testar com PDFs reais
- [ ] Economia esperada: ~60% apÃ³s primeiro upload

### Fase 3: Limpeza

#### 3.1. Groq Legacy
- [ ] Remover `src/lib/groq.ts` (nÃ£o usado)
- [ ] Remover imports obsoletos

#### 3.2. Unificar Tracking
- [ ] Garantir que TODAS as APIs salvam em `gateway_usage_logs`
- [ ] Deprecar `usage_logs` (legacy)
- [ ] Migrar dados histÃ³ricos se necessÃ¡rio

---

## ğŸ¯ BenefÃ­cios Esperados da MigraÃ§Ã£o Completa

### Economia de Custos

**Whisper:**
- Sem prompt cache (API de Ã¡udio)
- BenefÃ­cio: centralizaÃ§Ã£o + dashboard

**Embeddings:**
- Sem prompt cache (nÃ£o Ã© chat)
- BenefÃ­cio: centralizaÃ§Ã£o + dashboard

**Vision:**
- âœ… Prompt cache: ~60% economia (prompt repetido)
- Exemplo: "Descreva esta imagem" cacheado

**PDF Summary:**
- âœ… Prompt cache: ~70% economia (prompt longo ~12K tokens)
- Economia em uploads sequenciais

### Outros BenefÃ­cios

- âœ… **Dashboard unificado** (Vercel)
- âœ… **Fallback automÃ¡tico** entre providers
- âœ… **Tracking centralizado** (`gateway_usage_logs`)
- âœ… **Budget control** por cliente
- âœ… **Cache metrics** (hit rate, tokens saved)

---

## ğŸ“Š Resumo Executivo Final

| API | Modelo | AÃ§Ã£o | Budget Tracking | Economia |
|-----|--------|------|-----------------|----------|
| **Chat** | gpt-4o-mini | âœ… No Gateway | âœ… Completo | 60-70% (ativo) |
| **Embeddings** | text-embedding-3-small | ğŸ”„ Migrar Gateway | â†’ Unificado | Dashboard |
| **Vision** | gpt-4o | ğŸ”„ Migrar Gateway | â†’ Unificado | ~60% (cache) |
| **PDF Summary** | gpt-4o | ğŸ”„ Migrar Gateway | â†’ Unificado | ~70% (cache) |
| **Whisper** | whisper-1 | âš ï¸ Direto + Tracking | ğŸ”§ Melhorar | Dashboard |
| **TTS** | tts-1-hd | âš ï¸ Direto + Tracking | ğŸ”§ Melhorar | Dashboard |
| **ElevenLabs** | eleven_multilingual_v1 | âš ï¸ Direto | âœ… OK | - |

---

## ğŸ” Como Verificar Suporte do Gateway

### Teste rÃ¡pido:

```bash
# Testar Whisper
curl http://localhost:3000/api/test/gateway-whisper

# Testar Embeddings
curl http://localhost:3000/api/test/gateway-embeddings

# Testar Vision
curl http://localhost:3000/api/test/gateway-vision
```

### Consultar documentaÃ§Ã£o:

- [Vercel AI SDK - Audio](https://sdk.vercel.ai/docs/ai-sdk-core/audio)
- [Vercel AI SDK - Embeddings](https://sdk.vercel.ai/docs/ai-sdk-core/embeddings)
- [Vercel AI Gateway](https://vercel.com/docs/ai-gateway)

---

## ğŸ“ Notas TÃ©cnicas

### Por que TTS deve ficar direto:

1. **API diferente** (retorna Ã¡udio binÃ¡rio, nÃ£o texto)
2. **JÃ¡ tem cache prÃ³prio** (`tts_cache` table com hit rate alto)
3. **Gateway nÃ£o suporta** (foco em text generation)
4. **Tracking jÃ¡ unificado** (`trackUnifiedUsage()`)

### Por que ElevenLabs fica direto:

1. **Provider nÃ£o suportado** pelo Vercel AI Gateway
2. **API prÃ³pria** (nÃ£o Ã© OpenAI/Anthropic/Groq/Google)
3. **Uso baixo** (fallback opcional)

---

## âœ… Checklist de MigraÃ§Ã£o

### Antes de migrar qualquer API:

- [ ] Confirmar suporte do Gateway (docs/testes)
- [ ] Ler cÃ³digo atual e entender fluxo
- [ ] Identificar onde Ã© usado
- [ ] Estimar volume de uso
- [ ] Calcular economia esperada

### Durante migraÃ§Ã£o:

- [ ] Criar branch `feat/gateway-[api-name]`
- [ ] Implementar migraÃ§Ã£o
- [ ] Atualizar tracking para `gateway_usage_logs`
- [ ] Testar localmente
- [ ] Validar custos no dashboard
- [ ] Commit com mensagem clara

### ApÃ³s migraÃ§Ã£o:

- [ ] Deploy em staging
- [ ] Testar em produÃ§Ã£o (1 cliente)
- [ ] Monitorar dashboard Vercel (24h)
- [ ] Validar economia real
- [ ] Deploy para todos os clientes
- [ ] Documentar em changelog

---

**Ãšltima atualizaÃ§Ã£o:** 17/12/2024
**Autor:** Claude Code
**RevisÃ£o:** Pendente

# Plano TÃ©cnico: Feature de Ãudio/TTS (Text-to-Speech) - MODULAR

**Status:** ğŸ“‹ Planejamento v2.0
**Prioridade:** Alta
**Complexidade:** MÃ©dia-Alta
**Arquitetura:** **Modular, NÃ£o-Invasiva, TTS como Tool do AI**

---

## ğŸ¯ 1. VisÃ£o Geral - Abordagem Inteligente

### âŒ O QUE NÃƒO FAZER (VersÃ£o 1.0 - SubstituiÃ§Ã£o Global)
- Substituir TODAS as respostas por Ã¡udio (tudo ou nada)
- LÃ³gica rÃ­gida no `chatbotFlow.ts`
- Cliente nÃ£o pode escolher preferÃªncia
- Alto risco de crash/falha

### âœ… O QUE FAZER (VersÃ£o 2.0 - TTS como Tool do AI)

**TTS Ã© uma TOOL opcional que o prÃ³prio AI decide quando usar:**

```
Cliente: "Pode me explicar como funciona esse produto?"
AI: "Quer que eu explique por Ã¡udio? Fica mais fÃ¡cil de entender!"
Cliente: "Sim"
AI: <chama tool enviar_audio_explicacao>
```

**3 NÃ­veis de Controle:**
1. **Global (Empresa):** Ativar/desativar TTS para o tenant
2. **Cliente WhatsApp:** PreferÃªncia salva (quer Ã¡udio? sim/nÃ£o/perguntar)
3. **Contexto (AI):** Decide quando oferecer (explicaÃ§Ãµes longas, tutoriais)

---

## 2. Arquitetura Modular - TTS como Tool

### 2.1 Nova Tool para o AI Agent

```typescript
// Adicionar ao generateAIResponse.ts (tools do Groq)
{
  type: "function",
  function: {
    name: "enviar_resposta_em_audio",
    description: "Envia a resposta atual como mensagem de voz (Ã¡udio) ao invÃ©s de texto. Use quando:\n- ExplicaÃ§Ãµes longas (>200 caracteres)\n- Cliente solicitou Ã¡udio\n- Tutoriais ou passo-a-passo\n- Cliente tem preferÃªncia por Ã¡udio configurada\nNÃƒO use para: respostas curtas, perguntas rÃ¡pidas, confirmaÃ§Ãµes.",
    parameters: {
      type: "object",
      properties: {
        texto_para_audio: {
          type: "string",
          description: "Texto que serÃ¡ convertido em Ã¡udio (mÃ¡ximo 5000 caracteres)"
        },
        perguntar_antes: {
          type: "boolean",
          description: "Se true, pergunta ao cliente antes de enviar Ã¡udio (ex: 'Quer que eu explique por Ã¡udio?')"
        }
      },
      required: ["texto_para_audio"]
    }
  }
}
```

### 2.2 Fluxo Inteligente (AI decide)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cliente: "Como funciona o processo de devoluÃ§Ã£o?"           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI (Groq): Analisa contexto                                 â”‚
â”‚  - Resposta Ã© longa (>200 chars) âœ…                          â”‚
â”‚  - Cliente tem preferÃªncia "audio_enabled" âœ…               â”‚
â”‚  - Tipo de conteÃºdo: explicaÃ§Ã£o âœ…                          â”‚
â”‚                                                             â”‚
â”‚ DecisÃ£o: USAR TOOL enviar_resposta_em_audio                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ chatbotFlow.ts: Detecta tool call                          â”‚
â”‚  - Verifica se TTS estÃ¡ enabled (global)                    â”‚
â”‚  - Verifica preferÃªncia do cliente                          â”‚
â”‚  - Se perguntar_antes=true, envia pergunta primeiro         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NEW: handleAudioToolCall (handler especÃ­fico)               â”‚
â”‚  â”œâ”€ convertTextToSpeech (OpenAI TTS)                        â”‚
â”‚  â”œâ”€ uploadAudioToWhatsApp (Media API)                       â”‚
â”‚  â””â”€ sendWhatsAppMessage (type: audio) + FALLBACK           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FALLBACK ROBUSTO:                                           â”‚
â”‚  try { enviar Ã¡udio }                                       â”‚
â”‚  catch { enviar texto (mesma mensagem) }                    â”‚
â”‚  â†’ Nunca deixa cliente sem resposta!                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Database Schema - 3 NÃ­veis de ConfiguraÃ§Ã£o

### 3.1 Migration: ConfiguraÃ§Ã£o Global + PreferÃªncias

```sql
-- Migration 1: ConfiguraÃ§Ã£o global do tenant
ALTER TABLE clients
ADD COLUMN tts_enabled BOOLEAN DEFAULT false,
ADD COLUMN tts_provider TEXT DEFAULT 'openai' CHECK (tts_provider IN ('openai', 'elevenlabs', 'google')),
ADD COLUMN tts_voice TEXT DEFAULT 'alloy',
ADD COLUMN tts_speed NUMERIC DEFAULT 1.0 CHECK (tts_speed BETWEEN 0.25 AND 4.0),
ADD COLUMN tts_auto_offer BOOLEAN DEFAULT true; -- AI pode oferecer Ã¡udio automaticamente?

COMMENT ON COLUMN clients.tts_enabled IS 'Master switch: se false, TTS NUNCA serÃ¡ usado (ignora tool calls)';
COMMENT ON COLUMN clients.tts_auto_offer IS 'Se true, AI pode oferecer Ã¡udio. Se false, apenas se cliente pedir explicitamente';

-- Migration 2: PreferÃªncias por cliente WhatsApp
ALTER TABLE clientes_whatsapp
ADD COLUMN audio_preference TEXT DEFAULT 'ask' CHECK (audio_preference IN ('always', 'never', 'ask')),
ADD COLUMN last_audio_response_at TIMESTAMPTZ;

COMMENT ON COLUMN clientes_whatsapp.audio_preference IS 'always: sempre enviar Ã¡udio | never: nunca | ask: AI pergunta antes';

-- Migration 3: Cache de Ã¡udio
CREATE TABLE tts_cache (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  client_id UUID NOT NULL REFERENCES clients(id) ON DELETE CASCADE,
  text_hash TEXT NOT NULL, -- MD5 do texto
  audio_url TEXT NOT NULL, -- Supabase Storage ou CDN
  media_id TEXT, -- ID do WhatsApp (expira em 30 dias)
  provider TEXT NOT NULL,
  voice TEXT NOT NULL,
  duration_seconds INTEGER,
  file_size_bytes INTEGER,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  expires_at TIMESTAMPTZ DEFAULT NOW() + INTERVAL '7 days',
  hit_count INTEGER DEFAULT 0, -- Quantas vezes foi reusado
  UNIQUE(client_id, text_hash)
);

CREATE INDEX idx_tts_cache_expires ON tts_cache(expires_at);
CREATE INDEX idx_tts_cache_hits ON tts_cache(hit_count DESC);

-- RLS
ALTER TABLE tts_cache ENABLE ROW LEVEL SECURITY;
CREATE POLICY "Service role can access all TTS cache"
  ON tts_cache FOR ALL
  USING (auth.role() = 'service_role');
```

---

## 4. ImplementaÃ§Ã£o - Node & Tool Handler

### 4.1 Node: convertTextToSpeech.ts (Isolado, Modular)

```typescript
// src/nodes/convertTextToSpeech.ts
import OpenAI from 'openai'
import crypto from 'crypto'
import { createServerClient } from '@/lib/supabase/server'

export interface ConvertTextToSpeechInput {
  text: string
  clientId: string
  voice?: string
  speed?: number
  useCache?: boolean
}

export interface ConvertTextToSpeechOutput {
  audioBuffer: Buffer
  format: 'mp3'
  fromCache: boolean
  durationSeconds?: number
}

export const convertTextToSpeech = async (
  input: ConvertTextToSpeechInput
): Promise<ConvertTextToSpeechOutput> => {
  const { text, clientId, voice = 'alloy', speed = 1.0, useCache = true } = input

  // ValidaÃ§Ã£o: mÃ¡ximo 5000 caracteres
  if (text.length > 5000) {
    throw new Error('Text too long for TTS (max 5000 chars)')
  }

  // 1. Verificar cache
  if (useCache) {
    const textHash = crypto.createHash('md5').update(text + voice + speed).digest('hex')
    const supabase = createServerClient()

    const { data: cached } = await supabase
      .from('tts_cache')
      .select('audio_url, duration_seconds')
      .eq('client_id', clientId)
      .eq('text_hash', textHash)
      .gt('expires_at', new Date().toISOString())
      .single()

    if (cached) {
      // Cache hit! Atualizar contador
      await supabase
        .from('tts_cache')
        .update({ hit_count: supabase.rpc('increment', { row_id: textHash }) })
        .eq('text_hash', textHash)

      const response = await fetch(cached.audio_url)
      const audioBuffer = Buffer.from(await response.arrayBuffer())

      return {
        audioBuffer,
        format: 'mp3',
        fromCache: true,
        durationSeconds: cached.duration_seconds
      }
    }
  }

  // 2. Gerar Ã¡udio via OpenAI TTS
  const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
  })

  const mp3Response = await openai.audio.speech.create({
    model: 'tts-1-hd',
    voice: voice as 'alloy' | 'echo' | 'fable' | 'onyx' | 'nova' | 'shimmer',
    input: text,
    speed: speed,
    response_format: 'mp3'
  })

  const audioBuffer = Buffer.from(await mp3Response.arrayBuffer())

  // Estimar duraÃ§Ã£o (aproximado: 150 palavras/minuto)
  const wordCount = text.split(/\s+/).length
  const durationSeconds = Math.ceil((wordCount / 150) * 60)

  // 3. Salvar no cache
  if (useCache) {
    const supabase = createServerClient()
    const textHash = crypto.createHash('md5').update(text + voice + speed).digest('hex')
    const fileName = `${clientId}/${textHash}.mp3`

    // Upload para Supabase Storage
    const { error: uploadError } = await supabase.storage
      .from('tts-audio')
      .upload(fileName, audioBuffer, {
        contentType: 'audio/mpeg',
        upsert: true
      })

    if (!uploadError) {
      const { data: { publicUrl } } = supabase.storage
        .from('tts-audio')
        .getPublicUrl(fileName)

      await supabase.from('tts_cache').upsert({
        client_id: clientId,
        text_hash: textHash,
        audio_url: publicUrl,
        provider: 'openai',
        voice: voice,
        duration_seconds: durationSeconds,
        file_size_bytes: audioBuffer.length
      })
    }
  }

  return {
    audioBuffer,
    format: 'mp3',
    fromCache: false,
    durationSeconds
  }
}
```

### 4.2 Node: uploadAudioToWhatsApp.ts

```typescript
// src/nodes/uploadAudioToWhatsApp.ts
import FormData from 'form-data'

export interface UploadAudioToWhatsAppInput {
  audioBuffer: Buffer
  accessToken: string
  phoneNumberId: string
}

export interface UploadAudioToWhatsAppOutput {
  mediaId: string
  expiresAt: Date // WhatsApp media expira em 30 dias
}

export const uploadAudioToWhatsApp = async (
  input: UploadAudioToWhatsAppInput
): Promise<UploadAudioToWhatsAppOutput> => {
  const { audioBuffer, accessToken, phoneNumberId } = input

  const formData = new FormData()
  formData.append('file', audioBuffer, {
    filename: 'audio.mp3',
    contentType: 'audio/mpeg'
  })
  formData.append('messaging_product', 'whatsapp')

  const response = await fetch(
    `https://graph.facebook.com/v18.0/${phoneNumberId}/media`,
    {
      method: 'POST',
      headers: {
        Authorization: `Bearer ${accessToken}`
      },
      body: formData
    }
  )

  if (!response.ok) {
    const errorData = await response.json()
    throw new Error(`WhatsApp upload failed: ${JSON.stringify(errorData)}`)
  }

  const data = await response.json()

  // WhatsApp media expira em 30 dias
  const expiresAt = new Date()
  expiresAt.setDate(expiresAt.getDate() + 30)

  return {
    mediaId: data.id,
    expiresAt
  }
}
```

### 4.3 Handler: handleAudioToolCall.ts (NOVO)

```typescript
// src/handlers/handleAudioToolCall.ts
import { convertTextToSpeech } from '@/nodes/convertTextToSpeech'
import { uploadAudioToWhatsApp } from '@/nodes/uploadAudioToWhatsApp'
import { sendWhatsAppMessage } from '@/nodes/sendWhatsAppMessage'
import { createServerClient } from '@/lib/supabase/server'

export interface HandleAudioToolCallInput {
  texto_para_audio: string
  perguntar_antes?: boolean
  phone: string
  clientId: string
  clientConfig: any
}

export const handleAudioToolCall = async (
  input: HandleAudioToolCallInput
): Promise<{ success: boolean; sentAsAudio: boolean; error?: string }> => {
  const { texto_para_audio, perguntar_antes, phone, clientId, clientConfig } = input

  // 1. VerificaÃ§Ã£o de seguranÃ§a: TTS habilitado?
  if (!clientConfig.tts_enabled) {
    console.log('[TTS] Disabled globally, sending as text instead')
    return { success: false, sentAsAudio: false, error: 'TTS disabled' }
  }

  // 2. Verificar preferÃªncia do cliente
  const supabase = createServerClient()
  const { data: customer } = await supabase
    .from('clientes_whatsapp')
    .select('audio_preference')
    .eq('telefone', phone)
    .eq('client_id', clientId)
    .single()

  // Se cliente nÃ£o quer Ã¡udio, envia texto
  if (customer?.audio_preference === 'never') {
    console.log('[TTS] Customer preference is "never", sending as text')
    await sendWhatsAppMessage({
      phone,
      content: texto_para_audio,
      accessToken: clientConfig.meta_access_token,
      phoneNumberId: clientConfig.meta_phone_number_id,
      type: 'text'
    })
    return { success: true, sentAsAudio: false }
  }

  // 3. Se deve perguntar antes, envia pergunta e aguarda resposta
  if (perguntar_antes && customer?.audio_preference === 'ask') {
    await sendWhatsAppMessage({
      phone,
      content: 'Quer que eu explique isso por Ã¡udio? Responda "sim" ou "nÃ£o".',
      accessToken: clientConfig.meta_access_token,
      phoneNumberId: clientConfig.meta_phone_number_id,
      type: 'text'
    })
    // TODO: Implementar state machine para aguardar resposta
    // Por enquanto, envia texto
    return { success: true, sentAsAudio: false }
  }

  // 4. ENVIAR ÃUDIO com fallback robusto
  try {
    // 4.1 Converter para Ã¡udio
    const { audioBuffer, format, fromCache } = await convertTextToSpeech({
      text: texto_para_audio,
      clientId,
      voice: clientConfig.tts_voice || 'alloy',
      speed: clientConfig.tts_speed || 1.0,
      useCache: true
    })

    console.log(`[TTS] Audio generated (from cache: ${fromCache})`)

    // 4.2 Upload para WhatsApp
    const { mediaId } = await uploadAudioToWhatsApp({
      audioBuffer,
      accessToken: clientConfig.meta_access_token,
      phoneNumberId: clientConfig.meta_phone_number_id
    })

    console.log(`[TTS] Audio uploaded to WhatsApp: ${mediaId}`)

    // 4.3 Enviar mensagem de Ã¡udio
    await sendWhatsAppMessage({
      phone,
      content: texto_para_audio, // Salva texto no DB mesmo
      accessToken: clientConfig.meta_access_token,
      phoneNumberId: clientConfig.meta_phone_number_id,
      mediaId,
      type: 'audio'
    })

    // 4.4 Atualizar timestamp de Ãºltimo Ã¡udio
    await supabase
      .from('clientes_whatsapp')
      .update({ last_audio_response_at: new Date().toISOString() })
      .eq('telefone', phone)
      .eq('client_id', clientId)

    return { success: true, sentAsAudio: true }

  } catch (error) {
    // FALLBACK: Se QUALQUER erro, envia texto
    console.error('[TTS] Error generating/sending audio, falling back to text:', error)

    await sendWhatsAppMessage({
      phone,
      content: texto_para_audio,
      accessToken: clientConfig.meta_access_token,
      phoneNumberId: clientConfig.meta_phone_number_id,
      type: 'text'
    })

    return {
      success: true,
      sentAsAudio: false,
      error: error.message
    }
  }
}
```

---

## 5. IntegraÃ§Ã£o no chatbotFlow.ts (NÃƒO INVASIVO)

### 5.1 Adicionar Tool ao AI

```typescript
// src/nodes/generateAIResponse.ts (MODIFICAR TOOLS)

const tools = [
  {
    type: "function",
    function: {
      name: "transferir_atendimento",
      // ... cÃ³digo existente
    }
  },
  // NOVA TOOL
  {
    type: "function",
    function: {
      name: "enviar_resposta_em_audio",
      description: `Envia a resposta como mensagem de voz (Ã¡udio) ao invÃ©s de texto.

USE QUANDO:
- ExplicaÃ§Ãµes longas ou tutoriais (>200 caracteres)
- Cliente solicitou explicitamente Ã¡udio
- ConteÃºdo educacional ou passo-a-passo
- Cliente tem preferÃªncia por Ã¡udio

NÃƒO USE PARA:
- Respostas curtas (<100 caracteres)
- Perguntas simples
- ConfirmaÃ§Ãµes rÃ¡pidas
- Menus de opÃ§Ãµes`,
      parameters: {
        type: "object",
        properties: {
          texto_para_audio: {
            type: "string",
            description: "Texto que serÃ¡ convertido em Ã¡udio (mÃ¡ximo 5000 caracteres)"
          },
          perguntar_antes: {
            type: "boolean",
            description: "Se true, pergunta 'Quer que eu explique por Ã¡udio?' antes de enviar",
            default: false
          }
        },
        required: ["texto_para_audio"]
      }
    }
  }
]
```

### 5.2 Detectar Tool Call no Flow

```typescript
// src/flows/chatbotFlow.ts (ADICIONAR HANDLER)

import { handleAudioToolCall } from '@/handlers/handleAudioToolCall'

// ... dentro do flow, apÃ³s generateAIResponse

// NODE 11: Generate AI Response
const aiResponse = await generateAIResponse({
  chatHistory,
  relevantDocs,
  systemPrompt: clientConfig.system_prompt,
  // ...
})

// NOVO: Detectar tool calls
if (aiResponse.tool_calls && aiResponse.tool_calls.length > 0) {
  for (const toolCall of aiResponse.tool_calls) {
    if (toolCall.function.name === 'enviar_resposta_em_audio') {
      const args = JSON.parse(toolCall.function.arguments)

      // Handler especÃ­fico para Ã¡udio (com fallback)
      const result = await handleAudioToolCall({
        texto_para_audio: args.texto_para_audio,
        perguntar_antes: args.perguntar_antes || false,
        phone: normalizedMessage.phone,
        clientId,
        clientConfig
      })

      // Se enviou Ã¡udio com sucesso, nÃ£o precisa continuar flow
      if (result.sentAsAudio) {
        console.log('[Flow] Audio sent successfully, ending flow')
        return { success: true, sentAsAudio: true }
      }

      // Se falhou ou enviou texto, continua flow normalmente
      console.log('[Flow] Audio not sent, continuing with text flow')
      // Continua para FORMAT RESPONSE...
    }

    if (toolCall.function.name === 'transferir_atendimento') {
      // Handler existente
      // ...
    }
  }
}

// Continua flow normal (NODE 12: Format Response, etc.)
```

---

## 6. Prompt do AI (System Prompt) - InstruÃ§Ãµes sobre TTS

```typescript
// Adicionar ao system_prompt (em clients.system_prompt ou via dashboard)

const ttsInstructions = `
## Uso de Ãudio (TTS)

VocÃª tem uma ferramenta chamada "enviar_resposta_em_audio" que converte texto em mensagem de voz.

**Quando usar:**
- ExplicaÃ§Ãµes longas (>200 caracteres) que ficam melhores faladas
- Tutoriais ou instruÃ§Ãµes passo-a-passo
- Cliente pediu explicitamente Ã¡udio ("pode explicar por Ã¡udio?")
- ConteÃºdo educacional complexo

**Quando NÃƒO usar:**
- Respostas curtas (<100 caracteres)
- Listas ou menus de opÃ§Ãµes
- ConfirmaÃ§Ãµes simples ("ok", "entendi", etc.)
- InformaÃ§Ãµes que precisam ser lidas (telefones, links, cÃ³digos)

**Exemplo de uso correto:**
Cliente: "Como funciona o processo de devoluÃ§Ã£o?"
VocÃª: <chama enviar_resposta_em_audio com texto completo da explicaÃ§Ã£o>

**Exemplo incorreto:**
Cliente: "Qual o horÃ¡rio de funcionamento?"
VocÃª: <NÃƒO use TTS, responda em texto: "Funcionamos das 9h Ã s 18h">

Se nÃ£o tiver certeza, use perguntar_antes=true para pedir permissÃ£o ao cliente.
`
```

---

## 7. Dashboard UI - ConfiguraÃ§Ã£o Multi-NÃ­vel

### 7.1 ConfiguraÃ§Ã£o Global (Admin)

```tsx
// src/app/dashboard/settings/tts/page.tsx
export default function TTSSettingsPage() {
  const [config, setConfig] = useState({
    tts_enabled: false,
    tts_provider: 'openai',
    tts_voice: 'alloy',
    tts_speed: 1.0,
    tts_auto_offer: true
  })

  return (
    <div className="space-y-6">
      <h1>ConfiguraÃ§Ãµes de Ãudio (TTS)</h1>

      {/* Master Switch */}
      <Card>
        <CardHeader>
          <CardTitle>Ativar TTS (Master Switch)</CardTitle>
          <CardDescription>
            Se desativado, o bot NUNCA enviarÃ¡ Ã¡udios, mesmo que o AI tente
          </CardDescription>
        </CardHeader>
        <CardContent>
          <Switch
            checked={config.tts_enabled}
            onCheckedChange={(checked) => updateConfig('tts_enabled', checked)}
          />
        </CardContent>
      </Card>

      {/* Auto Offer */}
      <Card>
        <CardHeader>
          <CardTitle>Oferta AutomÃ¡tica de Ãudio</CardTitle>
          <CardDescription>
            Permite que o AI ofereÃ§a Ã¡udio automaticamente em contextos apropriados
          </CardDescription>
        </CardHeader>
        <CardContent>
          <Switch
            checked={config.tts_auto_offer}
            disabled={!config.tts_enabled}
            onCheckedChange={(checked) => updateConfig('tts_auto_offer', checked)}
          />
          <p className="text-sm text-muted-foreground mt-2">
            Se desativado, Ã¡udio sÃ³ serÃ¡ enviado se cliente pedir explicitamente
          </p>
        </CardContent>
      </Card>

      {/* ConfiguraÃ§Ã£o de Voz */}
      <Card>
        <CardHeader>
          <CardTitle>Voz e Velocidade</CardTitle>
        </CardHeader>
        <CardContent className="space-y-4">
          <div>
            <label>Voz</label>
            <Select
              value={config.tts_voice}
              onValueChange={(value) => updateConfig('tts_voice', value)}
              disabled={!config.tts_enabled}
            >
              <option value="alloy">Alloy (Neutro)</option>
              <option value="echo">Echo (Masculino)</option>
              <option value="fable">Fable (Feminino)</option>
              <option value="onyx">Onyx (Grave)</option>
              <option value="nova">Nova (EnergÃ©tico)</option>
              <option value="shimmer">Shimmer (Suave)</option>
            </Select>
          </div>

          <div>
            <label>Velocidade: {config.tts_speed}x</label>
            <Slider
              min={0.5}
              max={2.0}
              step={0.1}
              value={[config.tts_speed]}
              onValueChange={([value]) => updateConfig('tts_speed', value)}
              disabled={!config.tts_enabled}
            />
          </div>

          <button
            onClick={() => playPreview(config.tts_voice, config.tts_speed)}
            disabled={!config.tts_enabled}
          >
            ğŸ”Š Testar Voz
          </button>
        </CardContent>
      </Card>

      {/* EstatÃ­sticas */}
      <Card>
        <CardHeader>
          <CardTitle>EstatÃ­sticas de Uso</CardTitle>
        </CardHeader>
        <CardContent>
          <div className="grid gap-2">
            <div className="flex justify-between">
              <span>Ãudios enviados (mÃªs):</span>
              <span className="font-bold">1,234</span>
            </div>
            <div className="flex justify-between">
              <span>Cache hit rate:</span>
              <span className="font-bold text-green-600">67%</span>
            </div>
            <div className="flex justify-between">
              <span>Custo estimado:</span>
              <span className="font-bold">$8.50</span>
            </div>
            <div className="flex justify-between">
              <span>Economia com cache:</span>
              <span className="font-bold text-green-600">$17.20</span>
            </div>
          </div>
        </CardContent>
      </Card>
    </div>
  )
}
```

### 7.2 PreferÃªncias por Cliente (na conversa)

```tsx
// src/app/dashboard/conversations/[id]/page.tsx
// Adicionar botÃ£o na UI da conversa individual

<Card>
  <CardHeader>
    <CardTitle>PreferÃªncia de Ãudio</CardTitle>
  </CardHeader>
  <CardContent>
    <Select
      value={customer.audio_preference}
      onValueChange={(value) => updateCustomerPreference(value)}
    >
      <option value="always">Sempre enviar Ã¡udio</option>
      <option value="ask">Perguntar antes de enviar</option>
      <option value="never">Nunca enviar Ã¡udio</option>
    </Select>
  </CardContent>
</Card>
```

---

## 8. Vantagens desta Arquitetura Modular

| Aspecto | Abordagem Global (v1.0) | Abordagem Modular (v2.0) âœ… |
|---------|------------------------|----------------------------|
| **Risco de crash** | Alto (modifica flow principal) | Baixo (isolado, com fallback) |
| **Flexibilidade** | Tudo ou nada | 3 nÃ­veis de controle |
| **InteligÃªncia** | LÃ³gica rÃ­gida | AI decide contexto |
| **Custo** | Pode enviar Ã¡udio desnecessÃ¡rio | Otimizado (sÃ³ quando Ãºtil) |
| **UX** | Pode incomodar cliente | Cliente escolhe preferÃªncia |
| **ManutenÃ§Ã£o** | Acoplado ao flow | Desacoplado (fÃ¡cil remover) |

---

## 9. Casos de Uso - Exemplos Reais

### Caso 1: ExplicaÃ§Ã£o Longa (AI oferece Ã¡udio)

```
Cliente: "Como funciona o processo de devoluÃ§Ã£o do produto?"

AI (interno): Esta Ã© uma explicaÃ§Ã£o longa, vou oferecer Ã¡udio
AI: "Quer que eu explique o processo de devoluÃ§Ã£o por Ã¡udio? Fica mais fÃ¡cil!"

Cliente: "Sim"

AI: <chama enviar_resposta_em_audio com texto completo>
[Cliente recebe Ã¡udio de 90 segundos]
```

### Caso 2: Pergunta RÃ¡pida (AI envia texto)

```
Cliente: "Qual o horÃ¡rio de funcionamento?"

AI (interno): Resposta curta, nÃ£o precisa Ã¡udio
AI: "Funcionamos de segunda a sexta, das 9h Ã s 18h!"
[Envia texto normalmente]
```

### Caso 3: Cliente com PreferÃªncia "never"

```
Cliente: "Explica como usar o produto" [audio_preference = never]

AI: <tenta chamar enviar_resposta_em_audio>
Handler: Detecta preferÃªncia "never", envia texto automaticamente
[Cliente recebe texto mesmo sendo explicaÃ§Ã£o longa]
```

### Caso 4: Fallback (TTS falha)

```
Cliente: "Me explica isso"

AI: <chama enviar_resposta_em_audio>
TTS: [ERRO: OpenAI API timeout]
Handler: Detecta erro, fallback para texto
[Cliente recebe texto SEM PERCEBER que houve falha]
```

---

## 10. Testes de SeguranÃ§a

### Checklist de NÃ£o-Crash

- [ ] TTS desabilitado globalmente â†’ Ignora tool calls, envia texto
- [ ] OpenAI API falha â†’ Fallback para texto
- [ ] WhatsApp upload falha â†’ Fallback para texto
- [ ] Texto vazio â†’ Retorna erro, nÃ£o gera Ã¡udio
- [ ] Texto >5000 chars â†’ Trunca ou retorna erro
- [ ] Cliente sem preferÃªncia â†’ Usa padrÃ£o "ask"
- [ ] Network timeout â†’ Fallback apÃ³s 10s
- [ ] Ãudio corrompido â†’ Detecta, envia texto

---

## 11. ImplementaÃ§Ã£o em Fases

### Phase 1: Core Infrastructure (Semana 1)
1. âœ… Migration do banco (configs + cache)
2. âœ… Node `convertTextToSpeech.ts`
3. âœ… Node `uploadAudioToWhatsApp.ts`
4. âœ… Modificar `sendWhatsAppMessage.ts` (adicionar type: audio)
5. âœ… Criar handler `handleAudioToolCall.ts`
6. âœ… Testar isoladamente (endpoint /api/test/tts)

### Phase 2: AI Integration (Semana 2)
1. âœ… Adicionar tool ao `generateAIResponse.ts`
2. âœ… Integrar handler no `chatbotFlow.ts`
3. âœ… Adicionar instruÃ§Ãµes ao system prompt
4. âœ… Testar com conversas reais

### Phase 3: UI & Controls (Semana 3)
1. âœ… Dashboard de configuraÃ§Ã£o global
2. âœ… PreferÃªncias por cliente
3. âœ… EstatÃ­sticas de uso
4. âœ… Preview de vozes

### Phase 4: Optimization (Semana 4)
1. âœ… Cache inteligente
2. âœ… Monitoramento de custos
3. âœ… A/B testing (texto vs Ã¡udio)
4. âœ… Feedback do cliente (Ãºtil?)

---

## 12. Custos Reais (Otimizado)

### CenÃ¡rio: 10,000 conversas/mÃªs

| MÃ©trica | Sem TTS Tool | Com TTS Tool (AI decide) |
|---------|--------------|-------------------------|
| Mensagens totais | 10,000 | 10,000 |
| Ãudios enviados | 0 | ~2,000 (20% das conversas) |
| Cache hit rate | - | 60% |
| Ãudios gerados | 0 | 800 (40% sÃ£o novos) |
| Custo TTS | $0 | $12 (800 Ã¡udios Ã— 500 chars Ã— $15/1M) |
| **Custo total** | **$0** | **$12/mÃªs** |

**Economia vs. TTS sempre ativo:** $63/mÃªs (84% de economia!)

---

## 13. Monitoramento e Logs

```typescript
// src/lib/monitoring/ttsMetrics.ts
export const logTTSUsage = async (event: {
  type: 'generated' | 'cached' | 'failed' | 'fallback'
  clientId: string
  phone: string
  textLength: number
  fromCache?: boolean
  error?: string
}) => {
  // Log para analytics
  await supabase.from('tts_usage_logs').insert({
    event_type: event.type,
    client_id: event.clientId,
    phone: event.phone,
    text_length: event.textLength,
    from_cache: event.fromCache,
    error_message: event.error,
    timestamp: new Date()
  })
}
```

---

## 14. PersistÃªncia de Mensagens de Ãudio + UI Frontend

### 14.1 Database: Salvar Mensagens de Ãudio

**Tabela `messages` jÃ¡ existe, adicionar campos para Ã¡udio:**

```sql
-- Migration: Adicionar campos de Ã¡udio Ã  tabela messages
ALTER TABLE messages
ADD COLUMN media_id TEXT, -- WhatsApp media ID
ADD COLUMN media_url TEXT, -- URL do Ã¡udio (Supabase Storage ou WhatsApp)
ADD COLUMN media_type TEXT CHECK (media_type IN ('audio', 'image', 'video', 'document')),
ADD COLUMN transcription TEXT, -- Texto da mensagem (mesmo que Ã¡udio)
ADD COLUMN audio_duration_seconds INTEGER;

COMMENT ON COLUMN messages.media_id IS 'WhatsApp media ID (expira em 30 dias)';
COMMENT ON COLUMN messages.media_url IS 'URL permanente do Ã¡udio (Supabase Storage)';
COMMENT ON COLUMN messages.transcription IS 'TranscriÃ§Ã£o do Ã¡udio (para busca e exibiÃ§Ã£o)';

-- Ãndice para busca por transcriÃ§Ã£o
CREATE INDEX idx_messages_transcription ON messages USING GIN (to_tsvector('portuguese', transcription));
```

### 14.2 Modificar handleAudioToolCall: Salvar Mensagem

```typescript
// src/handlers/handleAudioToolCall.ts (ADICIONAR PERSISTÃŠNCIA)

export const handleAudioToolCall = async (input: HandleAudioToolCallInput) => {
  // ... cÃ³digo existente (gera Ã¡udio, upload)

  try {
    // 4.1 Converter para Ã¡udio
    const { audioBuffer, format, fromCache, durationSeconds } = await convertTextToSpeech({
      text: texto_para_audio,
      clientId,
      voice: clientConfig.tts_voice || 'alloy',
      speed: clientConfig.tts_speed || 1.0,
      useCache: true
    })

    // 4.2 Upload para WhatsApp
    const { mediaId, expiresAt } = await uploadAudioToWhatsApp({
      audioBuffer,
      accessToken: clientConfig.meta_access_token,
      phoneNumberId: clientConfig.meta_phone_number_id
    })

    // 4.2.1 Upload permanente para Supabase Storage (backup)
    const supabase = createServerClient()
    const fileName = `audio/${clientId}/${Date.now()}.mp3`

    const { error: storageError } = await supabase.storage
      .from('message-media')
      .upload(fileName, audioBuffer, {
        contentType: 'audio/mpeg',
        cacheControl: '31536000' // 1 ano
      })

    let permanentAudioUrl = null
    if (!storageError) {
      const { data: { publicUrl } } = supabase.storage
        .from('message-media')
        .getPublicUrl(fileName)
      permanentAudioUrl = publicUrl
    }

    // 4.3 Enviar mensagem de Ã¡udio
    await sendWhatsAppMessage({
      phone,
      content: texto_para_audio,
      accessToken: clientConfig.meta_access_token,
      phoneNumberId: clientConfig.meta_phone_number_id,
      mediaId,
      type: 'audio'
    })

    // âœ… 4.4 SALVAR NA TABELA MESSAGES
    const { data: conversation } = await supabase
      .from('conversations')
      .select('id')
      .eq('phone', phone)
      .eq('client_id', clientId)
      .single()

    if (conversation) {
      await supabase.from('messages').insert({
        client_id: clientId,
        conversation_id: conversation.id,
        phone,
        content: texto_para_audio, // Texto original
        transcription: texto_para_audio, // Mesma coisa (bot jÃ¡ gerou texto)
        type: 'audio',
        media_type: 'audio',
        media_id: mediaId,
        media_url: permanentAudioUrl,
        audio_duration_seconds: durationSeconds,
        direction: 'outbound', // Bot enviando
        status: 'sent',
        timestamp: new Date().toISOString(),
        metadata: {
          tts_voice: clientConfig.tts_voice,
          tts_speed: clientConfig.tts_speed,
          from_cache: fromCache,
          whatsapp_media_expires_at: expiresAt.toISOString()
        }
      })
    }

    // 4.5 Atualizar Ãºltima mensagem da conversa
    await supabase
      .from('conversations')
      .update({
        last_message: `ğŸ™ï¸ Ãudio (${durationSeconds}s)`,
        last_update: new Date().toISOString()
      })
      .eq('id', conversation.id)

    return { success: true, sentAsAudio: true }

  } catch (error) {
    // FALLBACK: envia texto e salva como mensagem de texto
    console.error('[TTS] Error, falling back to text:', error)

    await sendWhatsAppMessage({
      phone,
      content: texto_para_audio,
      accessToken: clientConfig.meta_access_token,
      phoneNumberId: clientConfig.meta_phone_number_id,
      type: 'text'
    })

    // Salvar como mensagem de texto
    const { data: conversation } = await supabase
      .from('conversations')
      .select('id')
      .eq('phone', phone)
      .eq('client_id', clientId)
      .single()

    if (conversation) {
      await supabase.from('messages').insert({
        client_id: clientId,
        conversation_id: conversation.id,
        phone,
        content: texto_para_audio,
        type: 'text',
        direction: 'outbound',
        status: 'sent',
        timestamp: new Date().toISOString(),
        metadata: {
          tts_fallback: true,
          tts_error: error.message
        }
      })
    }

    return { success: true, sentAsAudio: false, error: error.message }
  }
}
```

### 14.3 Frontend: Componente AudioMessage

```tsx
// src/components/AudioMessage.tsx
'use client'

import { useState, useRef, useEffect } from 'react'
import { Play, Pause, Volume2, FileText } from 'lucide-react'

interface AudioMessageProps {
  audioUrl: string
  transcription: string
  durationSeconds: number
  direction: 'inbound' | 'outbound'
  timestamp: string
}

export const AudioMessage = ({
  audioUrl,
  transcription,
  durationSeconds,
  direction,
  timestamp
}: AudioMessageProps) => {
  const [isPlaying, setIsPlaying] = useState(false)
  const [currentTime, setCurrentTime] = useState(0)
  const [showTranscription, setShowTranscription] = useState(false)
  const audioRef = useRef<HTMLAudioElement>(null)

  const togglePlay = () => {
    if (audioRef.current) {
      if (isPlaying) {
        audioRef.current.pause()
      } else {
        audioRef.current.play()
      }
      setIsPlaying(!isPlaying)
    }
  }

  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60)
    const secs = Math.floor(seconds % 60)
    return `${mins}:${secs.toString().padStart(2, '0')}`
  }

  useEffect(() => {
    const audio = audioRef.current
    if (!audio) return

    const handleTimeUpdate = () => setCurrentTime(audio.currentTime)
    const handleEnded = () => setIsPlaying(false)

    audio.addEventListener('timeupdate', handleTimeUpdate)
    audio.addEventListener('ended', handleEnded)

    return () => {
      audio.removeEventListener('timeupdate', handleTimeUpdate)
      audio.removeEventListener('ended', handleEnded)
    }
  }, [])

  return (
    <div
      className={`flex flex-col gap-2 max-w-md ${
        direction === 'outbound' ? 'ml-auto bg-blue-500 text-white' : 'bg-gray-200'
      } rounded-lg p-3`}
    >
      {/* Player de Ãudio */}
      <div className="flex items-center gap-3">
        {/* BotÃ£o Play/Pause */}
        <button
          onClick={togglePlay}
          className="w-10 h-10 rounded-full bg-white/20 hover:bg-white/30 flex items-center justify-center transition"
        >
          {isPlaying ? (
            <Pause className="w-5 h-5" />
          ) : (
            <Play className="w-5 h-5 ml-0.5" />
          )}
        </button>

        {/* Waveform / Progress */}
        <div className="flex-1">
          <div className="relative h-8 flex items-center gap-0.5">
            {/* Barras de waveform simuladas */}
            {Array.from({ length: 20 }).map((_, i) => {
              const height = Math.random() * 100
              const progress = (currentTime / durationSeconds) * 100
              const barProgress = (i / 20) * 100
              const isPlayed = barProgress < progress

              return (
                <div
                  key={i}
                  className="flex-1 rounded-full transition-all"
                  style={{
                    height: `${height}%`,
                    backgroundColor: isPlayed
                      ? direction === 'outbound'
                        ? 'white'
                        : '#3b82f6'
                      : 'rgba(255,255,255,0.3)',
                    minHeight: '4px'
                  }}
                />
              )
            })}
          </div>

          {/* Tempo */}
          <div className="flex justify-between text-xs opacity-75 mt-1">
            <span>{formatTime(currentTime)}</span>
            <span>{formatTime(durationSeconds)}</span>
          </div>
        </div>

        {/* Ãcone Volume */}
        <Volume2 className="w-4 h-4 opacity-75" />
      </div>

      {/* BotÃ£o Mostrar TranscriÃ§Ã£o */}
      <button
        onClick={() => setShowTranscription(!showTranscription)}
        className="flex items-center gap-2 text-xs opacity-75 hover:opacity-100 transition"
      >
        <FileText className="w-3 h-3" />
        {showTranscription ? 'Ocultar' : 'Mostrar'} transcriÃ§Ã£o
      </button>

      {/* TranscriÃ§Ã£o (expansÃ­vel) */}
      {showTranscription && (
        <div className="text-sm border-t border-white/20 pt-2 mt-1">
          <p className="italic opacity-90">{transcription}</p>
        </div>
      )}

      {/* Audio element (invisÃ­vel) */}
      <audio ref={audioRef} src={audioUrl} preload="metadata" />

      {/* Timestamp */}
      <span className="text-xs opacity-60 text-right">
        {new Date(timestamp).toLocaleTimeString('pt-BR', {
          hour: '2-digit',
          minute: '2-digit'
        })}
      </span>
    </div>
  )
}
```

### 14.4 Integrar no MessageBubble Existente

```tsx
// src/components/MessageBubble.tsx (MODIFICAR)
import { AudioMessage } from './AudioMessage'

export const MessageBubble = ({ message }: { message: Message }) => {
  // Se for mensagem de Ã¡udio, usar componente especÃ­fico
  if (message.media_type === 'audio' && message.media_url) {
    return (
      <AudioMessage
        audioUrl={message.media_url}
        transcription={message.transcription || message.content}
        durationSeconds={message.audio_duration_seconds || 0}
        direction={message.direction}
        timestamp={message.timestamp}
      />
    )
  }

  // Mensagem de texto normal (cÃ³digo existente)
  return (
    <div className={/* ... */}>
      {message.content}
    </div>
  )
}
```

### 14.5 Busca por TranscriÃ§Ã£o

```typescript
// src/app/api/conversations/search/route.ts
export async function GET(request: NextRequest) {
  const { searchParams } = new URL(request.url)
  const query = searchParams.get('q')

  const supabase = createServerClient()

  // Busca em mensagens de TEXTO e TRANSCRIÃ‡Ã•ES de Ã¡udio
  const { data } = await supabase
    .from('messages')
    .select('*')
    .or(`content.ilike.%${query}%,transcription.ilike.%${query}%`)
    .order('timestamp', { ascending: false })

  return NextResponse.json({ messages: data })
}
```

### 14.6 Dashboard: Filtro de Mensagens de Ãudio

```tsx
// src/app/dashboard/conversations/[id]/page.tsx
export default function ConversationPage() {
  const [filterType, setFilterType] = useState<'all' | 'text' | 'audio'>('all')

  const filteredMessages = messages.filter(msg => {
    if (filterType === 'all') return true
    if (filterType === 'audio') return msg.media_type === 'audio'
    if (filterType === 'text') return msg.type === 'text'
    return true
  })

  return (
    <div>
      {/* Filtro */}
      <div className="flex gap-2 mb-4">
        <button onClick={() => setFilterType('all')}>
          Todas ({messages.length})
        </button>
        <button onClick={() => setFilterType('text')}>
          ğŸ“ Texto ({messages.filter(m => m.type === 'text').length})
        </button>
        <button onClick={() => setFilterType('audio')}>
          ğŸ™ï¸ Ãudio ({messages.filter(m => m.media_type === 'audio').length})
        </button>
      </div>

      {/* Lista de Mensagens */}
      {filteredMessages.map(message => (
        <MessageBubble key={message.id} message={message} />
      ))}
    </div>
  )
}
```

### 14.7 Realtime: Atualizar UI quando Ãudio Chega

```typescript
// src/hooks/useRealtimeMessages.ts (MODIFICAR)
useEffect(() => {
  const channel = supabase
    .channel(`conversation:${conversationId}`)
    .on(
      'postgres_changes',
      {
        event: 'INSERT',
        schema: 'public',
        table: 'messages',
        filter: `conversation_id=eq.${conversationId}`
      },
      (payload) => {
        const newMessage = payload.new

        // Se for Ã¡udio, tocar som de notificaÃ§Ã£o diferente
        if (newMessage.media_type === 'audio') {
          playAudioNotificationSound()
        } else {
          playTextNotificationSound()
        }

        setMessages(prev => [...prev, newMessage])
      }
    )
    .subscribe()

  return () => {
    channel.unsubscribe()
  }
}, [conversationId])
```

### 14.8 Exportar Conversas (incluindo Ã¡udios)

```typescript
// src/app/api/conversations/[id]/export/route.ts
export async function GET(
  request: NextRequest,
  { params }: { params: { id: string } }
) {
  const { data: messages } = await supabase
    .from('messages')
    .select('*')
    .eq('conversation_id', params.id)
    .order('timestamp', { ascending: true })

  // Gerar PDF ou JSON com links de Ã¡udio
  const exportData = messages.map(msg => ({
    timestamp: msg.timestamp,
    direction: msg.direction,
    type: msg.media_type || msg.type,
    content: msg.transcription || msg.content,
    audioUrl: msg.media_type === 'audio' ? msg.media_url : null
  }))

  return NextResponse.json(exportData)
}
```

---

## 15. PrÃ³ximos Passos (Ordem de ImplementaÃ§Ã£o)

1. **Criar migrations** (configs + cache + preferÃªncias)
2. **Implementar nodes isolados** (TTS, upload)
3. **Testar nodes** via `/api/test/tts`
4. **Criar handler com fallback**
5. **Adicionar tool ao AI**
6. **Integrar no flow** (nÃ£o-invasivo)
7. **Dashboard de configuraÃ§Ã£o**
8. **Testar end-to-end** com WhatsApp real
9. **Monitorar custos** primeiros dias
10. **Ajustar system prompt** baseado em uso

---

**Criado em:** 2025-12-04 (v2.0 - Modular)
**Autor:** Claude Code
**VersÃ£o:** 2.0 (Arquitetura Inteligente)
**AprovaÃ§Ã£o:** âœ… Arquitetura nÃ£o-invasiva, modular, com fallback robusto
